# src/core/data/loader.py - VERSI√ìN SIMPLIFICADA FINAL

import json
import time
from pathlib import Path
from typing import List, Optional, Dict, Any
import logging

logger = logging.getLogger(__name__)


class FastDataLoader:
    """
    Cargador optimizado que usa settings como √∫nica fuente de verdad.
    Elimina toda duplicaci√≥n de configuraci√≥n ML.
    """

    def __init__(
        self,
        *,
        raw_dir: Optional[Path] = None,
        processed_dir: Optional[Path] = None,
        cache_enabled: bool = False,
        max_products_per_file: int = 500000,
        use_progress_bar: bool = True,
        # üî• ELIMINADO: Par√°metros ML redundantes
        # La configuraci√≥n ML viene de settings autom√°ticamente
    ):
        # Importar settings despu√©s de definir la clase
        from src.core.config import settings
        
        self.raw_dir = Path(raw_dir) if raw_dir else settings.RAW_DIR
        self.processed_dir = Path(processed_dir) if processed_dir else settings.PROC_DIR
        self.cache_enabled = cache_enabled
        self.max_products_per_file = max_products_per_file
        self.use_progress_bar = use_progress_bar
        
        # üî• ELIMINADO: No m√°s configuraci√≥n ML duplicada
        # Todo viene de settings autom√°ticamente
        
        # Crear directorios
        self.raw_dir.mkdir(parents=True, exist_ok=True)
        self.processed_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"üìÇ FastDataLoader inicializado")
        logger.info(f"   ‚Ä¢ Raw dir: {self.raw_dir}")
        logger.info(f"   ‚Ä¢ Processed dir: {self.processed_dir}")
        logger.info(f"   ‚Ä¢ Cache: {'‚úÖ' if cache_enabled else '‚ùå'}")

    # --------------------------------------------------
    # M√©todo principal simplificado
    # --------------------------------------------------
    
    def load_data(self, output_file: Optional[Path] = None) -> List[Any]:
        """
        Carga datos usando configuraci√≥n global desde settings.
        
        Args:
            output_file: Archivo de salida opcional
            
        Returns:
            Lista de productos
        """
        from src.core.data.product import Product, create_product
        
        start_time = time.time()
        
        if output_file is None:
            output_file = self.processed_dir / "products.json"
        
        logger.info("üìä Iniciando carga de datos...")
        
        # Cargar archivos disponibles
        files = self._discover_data_files()
        
        if not files:
            logger.warning("‚ö†Ô∏è No se encontraron archivos de datos")
            return self._create_sample_data(output_file)
        
        logger.info(f"üìÅ Archivos encontrados: {len(files)}")
        
        # Procesar archivos
        all_products = []
        for file_path in files:
            try:
                file_products = self._process_file(file_path)
                if file_products:
                    all_products.extend(file_products)
                    logger.debug(f"   ‚Ä¢ {file_path.name}: {len(file_products)} productos")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error procesando {file_path.name}: {e}")
        
        if not all_products:
            logger.error("‚ùå No se pudieron cargar productos")
            return self._create_sample_data(output_file)
        
        # üî• IMPORTANTE: La configuraci√≥n ML est√° en settings
        # Product.from_dict() usar√° autom√°ticamente esta configuraci√≥n
        
        # Guardar productos
        self._save_products(all_products, output_file)
        
        elapsed_time = time.time() - start_time
        logger.info(f"‚úÖ Carga completada en {elapsed_time:.1f}s")
        logger.info(f"üì¶ Productos cargados: {len(all_products)}")
        
        return all_products
    
    # --------------------------------------------------
    # M√©todos de procesamiento de archivos
    # --------------------------------------------------
    
    def _discover_data_files(self) -> List[Path]:
        """Descubre archivos de datos en el directorio raw"""
        extensions = [".json", ".jsonl"]
        files = []
        
        for ext in extensions:
            files.extend(self.raw_dir.glob(f"*{ext}"))
        
        # Filtrar archivos v√°lidos
        valid_files = []
        for f in files:
            if f.exists() and f.stat().st_size > 0:
                valid_files.append(f)
        
        # Ordenar por tama√±o (m√°s grandes primero)
        valid_files.sort(key=lambda x: x.stat().st_size, reverse=True)
        
        return valid_files[:25]  # Limitar a 5 archivos
    
    def _process_file(self, file_path: Path) -> List[Any]:
        """Procesa un archivo individual"""
        from src.core.data.product import Product, create_product
        
        try:
            if file_path.suffix.lower() == ".jsonl":
                return self._process_jsonl(file_path)
            else:
                return self._process_json(file_path)
        except Exception as e:
            logger.error(f"‚ùå Error procesando {file_path.name}: {e}")
            return []
    
    def _process_json(self, file_path: Path) -> List[Any]:
        """Procesa archivo JSON"""
        from src.core.data.product import Product, create_product
        
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                data = json.load(f)
            
            if not isinstance(data, list):
                data = [data]
            
            products = []
            for i, item in enumerate(data):
                if i >= self.max_products_per_file:
                    break
                
                try:
                    # üî• USAR CONFIGURACI√ìN GLOBAL: create_product() usa settings autom√°ticamente
                    product = create_product(item)
                    products.append(product)
                except Exception as e:
                    logger.debug(f"   Saltando item inv√°lido: {e}")
                    continue
            
            return products
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå JSON inv√°lido en {file_path.name}: {e}")
            return []
        except Exception as e:
            logger.error(f"‚ùå Error procesando JSON {file_path.name}: {e}")
            return []
    
    def _process_jsonl(self, file_path: Path) -> List[Any]:
        """Procesa archivo JSONL"""
        from src.core.data.product import Product, create_product
        
        products = []
        line_count = 0
        
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                for line in f:
                    if line_count >= self.max_products_per_file:
                        break
                    
                    line = line.strip()
                    if not line:
                        continue
                    
                    try:
                        item = json.loads(line)
                        if isinstance(item, dict):
                            # üî• USAR CONFIGURACI√ìN GLOBAL
                            product = create_product(item)
                            products.append(product)
                            line_count += 1
                    except json.JSONDecodeError:
                        continue
                    except Exception as e:
                        logger.debug(f"   Error en l√≠nea: {e}")
                        continue
            
            return products
            
        except Exception as e:
            logger.error(f"‚ùå Error procesando JSONL {file_path.name}: {e}")
            return []
    
    # --------------------------------------------------
    # M√©todos de utilidad
    # --------------------------------------------------
    
    def _create_sample_data(self, output_file: Path) -> List[Any]:
        """Crea datos de muestra si no hay datos reales"""
        from src.core.data.product import create_product
        
        logger.info("üìù Creando datos de muestra...")
        
        sample_data = [
            {
                "title": "Aud√≠fonos Bluetooth Inal√°mbricos",
                "description": "Aud√≠fonos de alta calidad con cancelaci√≥n de ruido",
                "price": 89.99,
                "main_category": "Electronics",
                "product_type": "Headphones",
                "tags": ["wireless", "bluetooth", "noise-cancelling"]
            },
            {
                "title": "Libro de Programaci√≥n Python",
                "description": "Aprende Python desde cero hasta avanzado",
                "price": 39.99,
                "main_category": "Books",
                "product_type": "Programming",
                "tags": ["python", "programming", "education"]
            },
            {
                "title": "Mouse Inal√°mbrico para Computadora",
                "description": "Mouse ergon√≥mico con sensor √≥ptico de alta precisi√≥n",
                "price": 29.99,
                "main_category": "Electronics",
                "product_type": "Computer Accessories",
                "tags": ["wireless", "mouse", "ergonomic"]
            }
        ]
        
        products = []
        for item in sample_data:
            try:
                product = create_product(item)
                products.append(product)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error creando producto de muestra: {e}")
        
        self._save_products(products, output_file)
        
        logger.info(f"‚úÖ Datos de muestra creados: {len(products)} productos")
        return products
    
    def _save_products(self, products: List[Any], output_file: Path) -> None:
        """Guarda productos en archivo"""
        try:
            # Convertir productos a diccionarios
            product_dicts = []
            for product in products:
                try:
                    if hasattr(product, 'model_dump'):
                        product_dicts.append(product.model_dump())
                    elif hasattr(product, 'dict'):
                        product_dicts.append(product.dict())
                    else:
                        # Intentar extraer atributos b√°sicos
                        product_dict = {
                            'id': getattr(product, 'id', ''),
                            'title': getattr(product, 'title', ''),
                            'description': getattr(product, 'description', ''),
                            'price': getattr(product, 'price', 0.0),
                            'main_category': getattr(product, 'main_category', ''),
                            'product_type': getattr(product, 'product_type', ''),
                        }
                        product_dicts.append(product_dict)
                except Exception as e:
                    logger.debug(f"   Error convirtiendo producto: {e}")
                    continue
            
            # Guardar en archivo
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(product_dicts, f, ensure_ascii=False, indent=2)
            
            logger.info(f"üíæ Productos guardados: {output_file}")
            
        except Exception as e:
            logger.error(f"‚ùå Error guardando productos: {e}")
    
    def _clean_product_data(self, item: Dict[str, Any]) -> Dict[str, Any]:
        """Limpia datos b√°sicos del producto"""
        cleaned = item.copy()
        
        # Asegurar campos requeridos
        cleaned.setdefault('title', 'Producto sin nombre')
        cleaned.setdefault('description', 'Sin descripci√≥n')
        cleaned.setdefault('price', 0.0)
        cleaned.setdefault('main_category', 'General')
        
        # Limpiar t√≠tulo
        title = cleaned['title']
        if isinstance(title, str):
            cleaned['title'] = title.strip()[:200]
        
        # Limpiar descripci√≥n
        description = cleaned['description']
        if isinstance(description, list):
            cleaned['description'] = ' '.join(str(x) for x in description[:3])
        elif not isinstance(description, str):
            cleaned['description'] = str(description)[:5000]
        
        # Asegurar que price sea num√©rico
        try:
            price = cleaned['price']
            if isinstance(price, str):
                # Extraer n√∫meros
                import re
                match = re.search(r'(\d+(?:[.,]\d+)?)', price)
                if match:
                    cleaned['price'] = float(match.group(1).replace(',', '.'))
                else:
                    cleaned['price'] = 0.0
            elif not isinstance(price, (int, float)):
                cleaned['price'] = 0.0
        except (ValueError, TypeError):
            cleaned['price'] = 0.0
        
        return cleaned
    
    # --------------------------------------------------
    # M√©todos de informaci√≥n y estad√≠sticas
    # --------------------------------------------------
    
    def get_stats(self) -> Dict[str, Any]:
        """Obtiene estad√≠sticas del loader"""
        from src.core.config import settings
        
        stats = {
            "raw_dir": str(self.raw_dir),
            "processed_dir": str(self.processed_dir),
            "max_products_per_file": self.max_products_per_file,
            "cache_enabled": self.cache_enabled,
            "total_products": self._get_total_products(),
            
            # üî• CONFIGURACI√ìN ML DESDE SETTINGS
            "ml_config": {
                "ml_enabled": settings.ML_ENABLED,
                "ml_features": list(settings.ML_FEATURES),
                "ml_categories": settings.ML_CATEGORIES[:5] if settings.ML_CATEGORIES else []
            }
        }
        
        return stats
    
    def _get_total_products(self) -> int:
        """Obtiene n√∫mero total de productos procesados"""
        output_file = self.processed_dir / "products.json"
        if output_file.exists():
            try:
                with open(output_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return len(data) if isinstance(data, list) else 0
            except Exception:
                return 0
        return 0
    
    def print_summary(self) -> None:
        """Imprime resumen del loader"""
        stats = self.get_stats()
        
        print("\n" + "="*60)
        print("üìä RESUMEN DEL FAST DATA LOADER")
        print("="*60)
        print(f"üìÇ Directorio raw: {stats['raw_dir']}")
        print(f"üìÅ Directorio procesado: {stats['processed_dir']}")
        print(f"üì¶ Productos totales: {stats['total_products']}")
        print(f"‚öôÔ∏è  M√°ximo por archivo: {stats['max_products_per_file']}")
        print(f"üíæ Cache: {'‚úÖ Activado' if stats['cache_enabled'] else '‚ùå Desactivado'}")
        
        ml_config = stats['ml_config']
        print(f"\nü§ñ CONFIGURACI√ìN ML:")
        print(f"   ‚Ä¢ Habilitado: {'‚úÖ S√≠' if ml_config['ml_enabled'] else '‚ùå No'}")
        if ml_config['ml_enabled']:
            print(f"   ‚Ä¢ Caracter√≠sticas: {', '.join(ml_config['ml_features'])}")
            print(f"   ‚Ä¢ Categor√≠as: {', '.join(ml_config['ml_categories'])}")
        print("="*60)


# ----------------------------------------------------------
# Alias para compatibilidad
# ----------------------------------------------------------

DataLoader = FastDataLoader


# ----------------------------------------------------------
# Funci√≥n de conveniencia
# ----------------------------------------------------------

def load_products(
    raw_dir: Optional[Path] = None,
    processed_dir: Optional[Path] = None,
    max_products: int = 500000
) -> List[Any]:
    """
    Funci√≥n de conveniencia para cargar productos.
    
    Args:
        raw_dir: Directorio de datos crudos
        processed_dir: Directorio de datos procesados
        max_products: M√°ximo de productos a cargar
        
    Returns:
        Lista de productos
    """
    from src.core.config import settings
    
    loader = FastDataLoader(
        raw_dir=raw_dir or settings.RAW_DIR,
        processed_dir=processed_dir or settings.PROC_DIR,
        max_products_per_file=max_products,
        cache_enabled=settings.CACHE_ENABLED
    )
    
    return loader.load_data()


# ----------------------------------------------------------
# Ejecuci√≥n directa (para pruebas)
# ----------------------------------------------------------

if __name__ == "__main__":
    import sys
    
    # Configurar logging b√°sico
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    print("üöÄ FastDataLoader - Prueba directa")
    print("="*50)
    
    try:
        # Cargar productos
        products = load_products(max_products=100)
        
        # Mostrar resumen
        if products:
            print(f"\n‚úÖ Carga exitosa: {len(products)} productos")
            
            # Mostrar primeros 3 productos
            print("\nüìã Primeros 3 productos:")
            for i, product in enumerate(products[:3]):
                title = getattr(product, 'title', 'Sin t√≠tulo')
                price = getattr(product, 'price', 0.0)
                category = getattr(product, 'main_category', 'General')
                
                print(f"   {i+1}. {title}")
                print(f"      Precio: ${price:.2f}")
                print(f"      Categor√≠a: {category}")
                print()
        else:
            print("‚ùå No se pudieron cargar productos")
            
    except Exception as e:
        print(f"‚ùå Error: {e}")
        sys.exit(1)