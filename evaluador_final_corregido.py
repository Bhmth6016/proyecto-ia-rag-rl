"""
Evaluador final CORREGIDO que usa ground truth REAL
"""
import json
import pickle
import numpy as np
import pandas as pd
from pathlib import Path

def calcular_precision(ranked_ids, relevant_ids, k=5):
    """Calcula Precision@k"""
    if not relevant_ids or k == 0:
        return 0.0
    top_k = ranked_ids[:k]
    relevant_in_top_k = sum(1 for pid in top_k if pid in relevant_ids)
    return relevant_in_top_k / k

def main():
    print("\n" + "="*80)
    print("ğŸ¯ EVALUADOR FINAL - CON GROUND TRUTH REAL")
    print("="*80)
    
    # 1. Cargar sistema con RL
    system_path = Path("data/cache/unified_system_with_fixed_rl.pkl")
    if not system_path.exists():
        print("âŒ Sistema no encontrado")
        return
    
    with open(system_path, 'rb') as f:
        system = pickle.load(f)
    
    print(f"âœ… Sistema cargado: {len(system.canonical_products):,} productos")
    
    # 2. Cargar ground truth REAL
    ground_truth_files = [
        Path("data/interactions/real_ground_truth.json"),
        Path("data/interactions/sample_ground_truth.json"),
        Path("data/interactions/relevance_labels.json")
    ]
    
    ground_truth = {}
    for gt_file in ground_truth_files:
        if gt_file.exists():
            try:
                with open(gt_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                if isinstance(data, dict):
                    # Unificar ground truth
                    for query, ids in data.items():
                        if query not in ground_truth:
                            ground_truth[query] = []
                        for pid in ids:
                            if pid not in ground_truth[query]:
                                ground_truth[query].append(pid)
                    print(f"âœ… Cargado: {gt_file.name} ({len(data)} queries)")
            except Exception as e:
                print(f"âš ï¸  Error cargando {gt_file.name}: {e}")
    
    if not ground_truth:
        print("âŒ No se encontrÃ³ ground truth")
        return
    
    print(f"ğŸ“Š Total queries con ground truth: {len(ground_truth)}")
    
    # 3. Evaluar cada query
    resultados = []
    queries_evaluadas = 0
    
    for query, relevant_ids in list(ground_truth.items())[:15]:  # MÃ¡ximo 15
        print(f"\nğŸ” Query: '{query}'")
        print(f"   â€¢ Productos relevantes: {len(relevant_ids)}")
        
        try:
            # Obtener embedding
            query_embedding = system.canonicalizer.embedding_model.encode(
                query, normalize_embeddings=True
            )
            
            # Baseline: buscar y ordenar por similitud
            baseline_results = system.vector_store.search(query_embedding, k=30)
            
            if not baseline_results:
                print("   âš ï¸  No hay resultados")
                continue
            
            # IDs baseline
            baseline_ids = [p.id for p in baseline_results[:10]]
            baseline_precision = calcular_precision(baseline_ids, relevant_ids, 5)
            
            # RL
            rl_ranker = system.rl_ranker
            if hasattr(rl_ranker, 'has_learned') and rl_ranker.has_learned:
                # Calcular scores baseline (similitud)
                baseline_scores = []
                for product in baseline_results:
                    if hasattr(product, 'similarity'):
                        baseline_scores.append(product.similarity)
                    else:
                        baseline_scores.append(0.5)
                
                # Aplicar RL
                rl_results = rl_ranker.rank_products(
                    baseline_results, query, baseline_scores
                )
                rl_ids = [p.id for p in rl_results[:10]]
                rl_precision = calcular_precision(rl_ids, relevant_ids, 5)
                
                # Verificar cambios
                changed = baseline_ids[:5] != rl_ids[:5]
                
                # Relevantes encontrados
                baseline_relevantes = sum(1 for pid in baseline_ids[:5] if pid in relevant_ids)
                rl_relevantes = sum(1 for pid in rl_ids[:5] if pid in relevant_ids)
                
                resultados.append({
                    'query': query,
                    'baseline_p@5': baseline_precision,
                    'rl_p@5': rl_precision,
                    'mejora': rl_precision - baseline_precision,
                    'mejora_porcentual': ((rl_precision - baseline_precision) / baseline_precision * 100) 
                                      if baseline_precision > 0 else 0,
                    'ranking_cambiado': changed,
                    'baseline_relevantes': baseline_relevantes,
                    'rl_relevantes': rl_relevantes,
                    'total_relevantes': len(relevant_ids)
                })
                
                queries_evaluadas += 1
                
                print(f"   ğŸ“Š Baseline: P@5={baseline_precision:.3f} ({baseline_relevantes}/{len(relevant_ids)})")
                print(f"   ğŸ¤– RL:       P@5={rl_precision:.3f} ({rl_relevantes}/{len(relevant_ids)})")
                print(f"   ğŸ“ˆ Mejora: {rl_precision - baseline_precision:+.3f}")
                
                if changed:
                    print(f"   ğŸ”€ Ranking ajustado")
                    # Mostrar cambios en top 3
                    for i in range(min(3, len(baseline_ids), len(rl_ids))):
                        if baseline_ids[i] != rl_ids[i]:
                            bl_product = next((p for p in baseline_results if p.id == baseline_ids[i]), None)
                            rl_product = next((p for p in rl_results if p.id == rl_ids[i]), None)
                            
                            bl_title = bl_product.title[:40] + "..." if bl_product and hasattr(bl_product, 'title') else "N/A"
                            rl_title = rl_product.title[:40] + "..." if rl_product and hasattr(rl_product, 'title') else "N/A"
                            
                            print(f"     Pos {i+1}: {bl_title} â†’ {rl_title}")
            
        except Exception as e:
            print(f"   âŒ Error: {e}")
            continue
    
    # 4. Resultados
    if resultados:
        df = pd.DataFrame(resultados)
        
        print("\n" + "="*80)
        print("ğŸ“ˆ RESULTADOS FINALES - RL MEJORADO")
        print("="*80)
        
        # MÃ©tricas promedio
        avg_baseline = df['baseline_p@5'].mean()
        avg_rl = df['rl_p@5'].mean()
        avg_mejora = df['mejora'].mean()
        avg_mejora_pct = df['mejora_porcentual'].mean()
        
        print(f"\nğŸ“Š PRECISIÃ“N@5 PROMEDIO:")
        print(f"   â€¢ Baseline (solo FAISS): {avg_baseline:.3f}")
        print(f"   â€¢ RL mejorado:           {avg_rl:.3f}")
        print(f"   â€¢ Mejora absoluta:       {avg_mejora:+.3f}")
        print(f"   â€¢ Mejora porcentual:     {avg_mejora_pct:+.1f}%")
        
        # Efectividad
        total_relevantes = df['total_relevantes'].sum()
        baseline_total = df['baseline_relevantes'].sum()
        rl_total = df['rl_relevantes'].sum()
        
        print(f"\nğŸ¯ EFECTIVIDAD EN RECUPERAR RELEVANTES:")
        print(f"   â€¢ Total relevantes: {total_relevantes}")
        print(f"   â€¢ Baseline recuperÃ³: {baseline_total} ({baseline_total/total_relevantes*100:.1f}%)")
        print(f"   â€¢ RL recuperÃ³:       {rl_total} ({rl_total/total_relevantes*100:.1f}%)")
        print(f"   â€¢ Diferencia:        {rl_total - baseline_total:+d} relevantes")
        
        # AnÃ¡lisis por queries
        mejoradas = len(df[df['mejora'] > 0])
        iguales = len(df[df['mejora'] == 0])
        empeoradas = len(df[df['mejora'] < 0])
        
        print(f"\nğŸ“ˆ DISTRIBUCIÃ“N:")
        print(f"   â€¢ Queries mejoradas:  {mejoradas}/{len(df)}")
        print(f"   â€¢ Queries iguales:    {iguales}/{len(df)}")
        print(f"   â€¢ Queries empeoradas: {empeoradas}/{len(df)}")
        
        if mejoradas > 0:
            top_mejoras = df.nlargest(3, 'mejora')
            print(f"\nğŸ† TOP 3 MEJORAS:")
            for _, row in top_mejoras.iterrows():
                print(f"   â€¢ '{row['query'][:30]}...': {row['baseline_p@5']:.3f} â†’ {row['rl_p@5']:.3f} "
                      f"(+{row['mejora']:.3f}, +{row['mejora_porcentual']:.1f}%)")
        
        # EstadÃ­sticas RL
        if hasattr(system.rl_ranker, 'get_stats'):
            rl_stats = system.rl_ranker.get_stats()
            print(f"\nğŸ¤– ESTADÃSTICAS DEL RL:")
            print(f"   â€¢ Feedback procesado: {rl_stats.get('feedback_count', 0)}")
            print(f"   â€¢ Features aprendidas: {rl_stats.get('weights_count', 0)}")
            print(f"   â€¢ Ratio match/rating:  {rl_stats.get('match_vs_rating_ratio', 0):.2f}")
            
            if 'top_features' in rl_stats and rl_stats['top_features']:
                print(f"   ğŸ” TOP 5 FEATURES:")
                for i, (feature, weight) in enumerate(rl_stats['top_features'][:5], 1):
                    if 'match' in feature.lower():
                        symbol = "ğŸ¯"
                    elif 'rating' in feature.lower():
                        symbol = "â­"
                    elif 'keyword' in feature.lower():
                        symbol = "ğŸ”‘"
                    else:
                        symbol = "ğŸ“Š"
                    
                    print(f"     {symbol} {feature:25} {weight:7.3f}")
        
        # Guardar
        output_file = "resultados_finales_corregidos.csv"
        df.to_csv(output_file, index=False)
        print(f"\nğŸ’¾ Resultados guardados en: {output_file}")
        
        # ConclusiÃ³n
        print(f"\nğŸ’¡ CONCLUSIÃ“N:")
        if avg_mejora_pct > 5:
            print(f"  âœ… Â¡EXCELENTE! RL mejora {avg_mejora_pct:+.1f}% sobre baseline")
            print(f"  âœ¨ El aprendizaje por refuerzo FUNCIONA correctamente")
        elif avg_mejora_pct > 0:
            print(f"  âœ… Mejora moderada: {avg_mejora_pct:+.1f}%")
            print(f"  ğŸ“ˆ El RL estÃ¡ aprendiendo pero puede mejorar con mÃ¡s feedback")
        elif avg_mejora_pct > -5:
            print(f"  âš ï¸  Sin mejora significativa: {avg_mejora_pct:+.1f}%")
            print(f"  ğŸ”§ Considerar ajustar parÃ¡metros de aprendizaje")
        else:
            print(f"  âŒ DegradaciÃ³n: {avg_mejora_pct:+.1f}%")
            print(f"  ğŸ›‘ Revisar el entrenamiento del RL")
    
    print("\n" + "="*80)
    print("âœ… EVALUACIÃ“N COMPLETADA")
    print("="*80)

if __name__ == "__main__":
    main()